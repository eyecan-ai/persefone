{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations import DualTransform\n",
    "import albumentations.pytorch.transforms as AT\n",
    "from PIL import Image\n",
    "import IPython\n",
    "import imageio\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def vis_points(image, points, diameter=1):\n",
    "    im = image.copy()\n",
    "    for (x, y) in points:\n",
    "        cv2.circle(im, (int(x), int(y)), diameter, (0, 255, 0), -1)\n",
    "    plt.figure()\n",
    "    plt.imshow(im)\n",
    "    \n",
    "    \n",
    "class CustomTransform(DualTransform):\n",
    "    \"\"\"Transform for segmentation task.\"\"\"\n",
    "    \n",
    "    def __init__(self, padding=[20,20,20,20], always_apply=False, p=1.0):\n",
    "        super(CustomTransform, self).__init__(always_apply, p)\n",
    "        self.padding = padding\n",
    "        \n",
    "    @property\n",
    "    def targets(self):\n",
    "        return {\n",
    "            \"image\": self.apply,\n",
    "            \"mask\": self.apply_to_mask,\n",
    "            \"masks\": self.apply_to_masks,\n",
    "            \"bboxes\": self.apply_to_bboxes,\n",
    "            \"keypoints\": self.apply_to_keypoints,\n",
    "        }\n",
    "\n",
    "    def apply(self, image, **params):\n",
    "        padding = self.padding\n",
    "        if padding[0]>0:\n",
    "            image[:,:padding[0],:] = 0\n",
    "        if padding[1]>0:\n",
    "            image[:padding[1],:,:] = 0\n",
    "        if padding[2]>0:\n",
    "            image[:, -padding[2]:,:] = 0\n",
    "        if padding[3]>0:\n",
    "            image[-padding[3]:,:,:] = 0\n",
    "            \n",
    "        return image\n",
    "        \n",
    "    def apply_to_bbox(self, bbox, **params):\n",
    "        raise NotImplementedError(\"Method apply_to_bbox is not implemented in class \" + self.__class__.__name__)\n",
    "\n",
    "    def apply_to_keypoint(self, keypoint, **params):\n",
    "        padding = self.padding\n",
    "        print(\"AP\", params)\n",
    "        x,y = keypoint[:2]\n",
    "        if x < padding[0]:\n",
    "            return (-1,-1,-1,-1)\n",
    "        if x > params['cols']-padding[2]:\n",
    "            return (-1,-1,-1,-1)\n",
    "        if y < padding[1]:\n",
    "            return (-1,-1,-1,-1)\n",
    "        if y > params['rows']-padding[3]:\n",
    "            return (-1,-1,-1,-1)\n",
    "        return keypoint\n",
    "\n",
    "    def apply_to_bboxes(self, bboxes, **params):\n",
    "        return [self.apply_to_bbox(tuple(bbox[:4]), **params) + tuple(bbox[4:]) for bbox in bboxes]\n",
    "\n",
    "    def apply_to_keypoints(self, keypoints, **params):\n",
    "        return [self.apply_to_keypoint(tuple(keypoint[:4]), **params) + tuple(keypoint[4:]) for keypoint in keypoints]\n",
    "\n",
    "    def apply_to_mask(self, img, **params):\n",
    "        return self.apply(img, **{k: cv2.INTER_NEAREST if k == \"interpolation\" else v for k, v in params.items()})\n",
    "\n",
    "    def apply_to_masks(self, masks, **params):\n",
    "        return [self.apply_to_mask(mask, **params) for mask in masks]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/daniele/work/workspace_python/cookiecutter_test/persefone/tests/sample_data/datasets/minimnist/000007_image.jpg'\n",
    "mask_path = '/Users/daniele/work/workspace_python/cookiecutter_test/persefone/tests/sample_data/datasets/minimnist/000007_image_mask.png'\n",
    "points_path = '/Users/daniele/work/workspace_python/cookiecutter_test/persefone/tests/sample_data/datasets/minimnist/000007_points.txt'\n",
    "image = imageio.imread(image_path)\n",
    "mask = (imageio.imread(mask_path).astype(float) /255. ).astype(np.uint8)\n",
    "points = np.loadtxt(points_path).reshape((-1,2))\n",
    "\n",
    "print(mask.min(), mask.max(),np.unique(mask))\n",
    "#print(points)\n",
    "#vis_points(image, points)\n",
    "\n",
    "r = A.Resize(height=64,width=64,p=1)\n",
    "rot = A.Rotate(limit=(-90,90),p=1)\n",
    "#aff = A.IAAPiecewiseAffine(p=1.0)\n",
    "aff = A.IAAPerspective(p=1.0)\n",
    "br = A.RandomBrightnessContrast(p=1.0)\n",
    "gig = A.RandomGridShuffle(p=1.0)\n",
    "print(gig.targets)\n",
    "my = CustomTransform(padding=[50,20,50,10],always_apply=True, p=0.0)\n",
    "#rot = A.RandomRotate90(p=1)\n",
    "T = A.Compose([r,br,aff],p=1, keypoint_params=A.KeypointParams(format='xy'))\n",
    "\n",
    "\n",
    "\n",
    "points = [(14,5),(14,25),(14,14)]\n",
    "results = T(image=image, mask=mask, keypoints=points)\n",
    "#results['mask'][results['mask']>0] = 255\n",
    "print(results['mask'].min(), results['mask'].max(), np.unique(results['mask']))\n",
    "vis_points(results['image'],results['keypoints'], diameter=1)\n",
    "vis_points(results['mask']*255,results['keypoints'], diameter=1)\n",
    "#vis_points(mask,pts, diameter=1)\n",
    "#IPython.display.display(Image.fromarray(image))\n",
    "#tt = AT.ToTensor()\n",
    "#tensor = tt(image=image)['image']\n",
    "#print(tensor.shape, tensor.min(), tensor.max())\n",
    "\n",
    "IPython.display.display(Image.fromarray(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/daniele/Downloads/Salvini-Di-Maio_botte-siÌ€-crisi-no.jpg'\n",
    "image = imageio.imread(image_path)\n",
    "\n",
    "r = A.Resize(height=256,width=256,p=1)\n",
    "c = A.Crop(50,50,200,200,always_apply=True)\n",
    "#my = CustomTransform(padding=[50,20,50,10],always_apply=True, p=0.0)\n",
    "#rot = A.RandomRotate90(p=1)\n",
    "T = A.Compose([r,c,r],p=1, keypoint_params=A.KeypointParams(format='xy'))\n",
    "\n",
    "image = T(image=image,mask=None, keypoints=[])['image']\n",
    "\n",
    "vis_points(image, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "persefone",
   "language": "python",
   "name": "persefone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
